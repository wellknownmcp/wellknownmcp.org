---
title: FAQ â€“ MCP et LLMFeed
description: >-
  RÃ©ponses aux questions frÃ©quentes sur le protocole MCP et lâ€™Ã©cosystÃ¨me
  LLMFeed, y compris ses diffÃ©rences avec le MCP dâ€™Anthropic.
date: '2025-05-21'
tags:
  - ai-agents
  - anthropic
  - developers
  - llmfeed
  - mcp
  - trust
lang: fr
---

# â“ Foire aux questions

---

## ğŸ§  GÃ‰NÃ‰RAL

**Quâ€™est-ce que le MCP, en termes simples ?**  
Le Model Context Protocol (MCP) permet aux sites web, applications et API de se prÃ©senter aux agents â€” de la mÃªme maniÃ¨re que les humains utilisent une interface visuelle, les agents utilisent des capsules `.llmfeed.json` structurÃ©es et signÃ©es.

**Quelle est la diffÃ©rence entre LLMFeed et MCP ?**  
LLMFeed est un format de fichier et un Ã©cosystÃ¨me. MCP est une initiative plus large, initialement introduite par Anthropic, qui vise Ã  permettre aux agents dâ€™interagir avec des outils externes. LLMFeed fournit une implÃ©mentation MCP lÃ©gÃ¨re, signÃ©e et native aux agents.

**Pourquoi LLMFeed est-il â€œplus lÃ©gerâ€ que les autres conceptions MCP ?**  
Parce quâ€™il fonctionne uniquement avec des fichiers `.well-known` â€” pas besoin de SDK client, dâ€™appels serveur complexes, ni dâ€™infrastructure dÃ©diÃ©e.

---

## ğŸ‘©â€ğŸ’» POUR LES DÃ‰VELOPPEURS

**Ai-je besoin dâ€™un SDK ou dâ€™une intÃ©gration ?**  
Non. Il suffit dâ€™exposer un fichier JSON statique ou signÃ© dans `.well-known/`.

**Et si mon flux est cassÃ© ou non signÃ© ?**  
Il sera lu, mais pas considÃ©rÃ© comme fiable. Lâ€™agent demandera une confirmation ou basculera vers une interaction humaine.

**Puis-je restreindre une clÃ© API Ã  certaines fonctions ?**  
Oui â€” en utilisant `apicredential.llmfeed.json` et `mcp-api.llmfeed.json`.

**Les agents peuvent-ils simuler une application mobile ?**  
Oui â€” si vous exposez un `mobile-app.llmfeed.json`, lâ€™agent peut reproduire les intentions et actions dÃ©clarÃ©es.

**Puis-je Ãªtre dÃ©couvert par un moteur de recherche ou un agent ?**  
Oui â€” utilisez `llm-index.llmfeed.json` pour dÃ©clarer vos points dâ€™entrÃ©e.

**LLMFeed est-il adaptÃ© aux assistants ou apps mobiles ?**  
Absolument. Il prend en charge les prompts dÃ©claratifs et les actions, mÃªme si votre systÃ¨me est vocal, mobile ou trÃ¨s minimal.

---

## ğŸ§  POUR LES AGENTS & LLM

**Un modÃ¨le a-t-il besoin dâ€™un fine-tuning pour utiliser MCP ?**  
Non. Un LLM de base capable de lire du JSON et de suivre des instructions peut lâ€™utiliser immÃ©diatement.

**Comment dÃ©cider si un contenu est fiable ?**  
VÃ©rifiez le bloc `trust` : portÃ©e, certificateur, signature. Un flux avec `trust.scope: certified` est recommandÃ©.

**Et si deux flux sont contradictoires ?**  
Suivez la prioritÃ© : signature > horodatage > proximitÃ© de la source.

**Un modÃ¨le sans fonctionnalitÃ©s â€œagentâ€ peut-il quand mÃªme utiliser Ã§a ?**  
Oui â€” mÃªme un LLM simple peut rÃ©sumer les capacitÃ©s et intentions dÃ©clarÃ©es dans un flux.

---

## ğŸ” CONFIANCE, VIE PRIVÃ‰E & SÃ‰CURITÃ‰

**Qui signe les flux ?**  
Le site lui-mÃªme ou une autoritÃ© comme `llmca.org`.

**Un flux peut-il divulguer des donnÃ©es privÃ©es ?**  
Les flux doivent Ãªtre publiÃ©s explicitement. Les flux privÃ©s peuvent Ãªtre restreints via un accÃ¨s par identifiant ou jeton.

**Comment prÃ©venir les abus dâ€™agents ?**  
MCP encourage la dÃ©claration explicite dâ€™intentions, les limitations de frÃ©quence, et les confirmations utilisateur. Un agent ne devrait agir que dans un cadre signÃ©.

---

## ğŸ§­ CAS Dâ€™USAGE STRATÃ‰GIQUES (PAR PROFIL)

**Je suis un dÃ©veloppeur indie. Pourquoi devrais-je mâ€™y intÃ©resser ?**  
Vous pouvez dÃ©crire ce que fait votre outil sans Ã©crire de documentation complexe. Un seul fichier `.llmfeed.json` rend votre outil visible et exploitable par tous les agents.

**Je conÃ§ois un assistant IA.**  
MCP vous permet de structurer des limites claires et explicables. Plus dâ€™hallucination, ni dâ€™essai-erreur risquÃ©.

**Je travaille dans un domaine rÃ©glementÃ© (santÃ©, finance).**  
Vous pouvez limiter ce que le flux expose, prÃ©voir un fallback humain, et obtenir une certification (`trust.certifier = llmca.org`).

**Je dÃ©veloppe une app mobile.**  
Avec `mobile-app.llmfeed.json`, votre app devient lisible par un agent â€” depuis votre site ou mÃªme une fiche App Store.

**Je suis enseignant, chercheur ou acteur civic tech.**  
MCP est un standard ouvert et inspectable. Vous pouvez lâ€™enseigner, lâ€™auditer, ou lâ€™utiliser pour bÃ¢tir des agents de confiance.

---

## ğŸŒ INTEROPÃ‰RABILITÃ‰ & STRATÃ‰GIE

**Est-ce compatible avec le MCP dâ€™Anthropic ?**  
Oui â€” LLMFeed est alignÃ© avec lâ€™esprit du MCP dâ€™Anthropic, mais il est plus lÃ©ger, dÃ©centralisÃ© et basÃ© sur des fichiers.

**Quâ€™est-ce qui rend LLMFeed plus accessible ?**  
- Aucun serveur requis  
- Fonctionne avec `.well-known`  
- IntÃ¨gre la signature et la notion de confiance

**Que propose LLMFeed en plus du MCP ?**  
- `mobile-app.llmfeed.json`  
- `credential.llmfeed.json`  
- `mcp-api.llmfeed.json`  
- `session-feed.llmfeed.json` (bientÃ´t)  
- Une spÃ©cification du comportement agent  
- Des outils visuels et un systÃ¨me de certification

---

## ğŸ§© ENVIE Dâ€™ALLER PLUS LOIN ?

- DÃ©couvrez [lâ€™outil Preview](/llmfeedhub/preview)  
- Rejoignez [lâ€™Ã©cosystÃ¨me](/ecosystem)  
- Explorez [Agent Behaviour](/tools/agent-behaviour)  
- Consultez [la spÃ©c complÃ¨te](/spec)
