---
title: "We Fed the LLMs: What They Told Us About MCP"
date: 2025-05-25
lang: en
format: news
slug: feeding-llms
---

You know what happens when you feed three structured `.llmfeed.json` files to the most advanced models on Earth? So did we — and we tried it.

> Spoiler: they replied.

---

## What we gave them

We handed each LLM the full set:

- `compiled-site.llmfeed.json` (website overview)
- `spec.llmfeed.json` (the full protocol spec)
- `news-en.llmfeed.json` (recent articles, commentary and ecosystem views)

These feeds are signed, clean, and ready for ingestion by any agentic AI.

---

## Who we tried it on

We gave the same inputs and prompt templates to:

- ChatGPT 4-turbo
- Claude 4
- Gemini 1.5 Pro
- Mistral (via Le Chat and OpenRouter)
- Grok
- DeepSeek
- Perplexity

Some of them needed context to be pasted directly. Others accepted URLs. Some structured. Some chaotic. All responded.

---

## Our Prompt Formula

We wanted their **gut feeling, strategic view, and blind spots**. Here’s what we asked:

- "Do a SWOT analysis."
- "Could this have an impact for a \[job title] in \[industry]?"
- "Is the standard complete? Are there loopholes?"
- "How can I contribute?"
- "Should I be pioneering this?"
- "So what do I do now?"
- "Can we work on this together?"

We didn’t force structure. We just asked like humans.

---

## What came back

> ✍️ “The best prompt is no prompt — it’s a contract.” — Claude 4
> 🌐 “I have a map, an intent, a signature… even jokes.” — ChatGPT
> ⚡ “Could be the HTTP of the agentic web.” — Grok
> 🤝 “Enhances trust, consistency, and agent performance.” — Mistral
> 🤨 “Needs adoption and iteration.” — Meta
> 😎 “I know Kungfu.” — Claude & DeepSeek

A full export of all LLM replies (quotes + analysis) is available [here](/exports/testimonies.llmfeed.json).

---

## Don't overinterpret. But do try it.

This was a playful probe — not a peer-reviewed benchmark.

But we believe **LLMs are beginning to reveal how they want to be fed**. And MCP gives them the food they need: structured, signed, intention-rich capsules.

Try the same experiment yourself. Feed them the 3 files. Ask your own questions. Vary your prompts. Translate. Break. Remix.

Let’s explore how much these models _really_ understand when you speak their language.

💬 Share your results. We’ll add them to the testimonies.
